[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Methods for Composite Endpoints",
    "section": "",
    "text": "Preface\nThis is a companion site for the same-titled workshop at the 2024 Society for Clinical Trials (SCT) Annual Meeting given on May 19, 2024 at Boston Marriott Copley Place in Boston, MA."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Statistical Methods for Composite Endpoints",
    "section": "Slides",
    "text": "Slides\nCourse information slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "regression.html#slides",
    "href": "regression.html#slides",
    "title": "4  Semiparametric Regression",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "intro.html#slides",
    "href": "intro.html#slides",
    "title": "1  Introduction",
    "section": "Slides",
    "text": "Slides\nChapter slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "testing.html#slides",
    "href": "testing.html#slides",
    "title": "2  Hypothesis Testing",
    "section": "Slides",
    "text": "Slides\nChapter slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "estimation.html#slides",
    "href": "estimation.html#slides",
    "title": "3  Nonparametric Estimation",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "discussions.html#slides",
    "href": "discussions.html#slides",
    "title": "5  Discussions",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "intro.html#r-code",
    "href": "intro.html#r-code",
    "title": "1  Introduction",
    "section": "R-code",
    "text": "R-code\n\n\nShow the code\n##################################################################\n# This code generates the numerical results in  chapter 1       ##\n##################################################################\n\n# load the survival package\nlibrary(survival)\n# install.packages(\"Wcompo\")\nlibrary(Wcompo) # for weighted total events\nlibrary(rmt) # for hfaction data\nlibrary(tidyverse) # for data wrangling\n\n# load hfaction data\ndata(hfaction)\nhead(hfaction)\n\n# convert status=1 for death, 2=hospitalization\nhfaction &lt;- hfaction |&gt; \n  mutate(\n    status = case_when(\n      status == 1 ~ 2,\n      status == 2 ~ 1,\n      status == 0 ~ 0\n    )\n  )\n\nhead(hfaction)\n\n# count unique patients in each arm\nhfaction |&gt; \n  group_by(trt_ab) |&gt; \n  distinct(patid) |&gt; \n  count(trt_ab)\n\n# TFE: take the first event per patient id\nhfaction_TFE &lt;- hfaction |&gt; \n  arrange(patid, time) |&gt; \n  group_by(patid) |&gt; \n  slice_head() |&gt; \n  ungroup()\n\n# Mortality analysis ------------------------------------------------------\n\n## get mortality data\nhfaction_D &lt;- hfaction |&gt; \n  filter(status != 2) # remove hospitalization records\n\n## Cox model for death against trt_ab\nobj_D &lt;- coxph(Surv(time, status) ~ trt_ab, data = hfaction_D)\nsummary(obj_D)\n#&gt; n= 426, number of events= 93 \n#&gt; coef exp(coef) se(coef)      z Pr(&gt;|z|)  \n#&gt; trt_ab -0.3973    0.6721   0.2129 -1.866   0.0621 .\n\n# TFE analysis --------------------------------------------------------\n\n## how many of first events are death (1) or hosp (2)\nhfaction_TFE |&gt; \n  count(status)\n\n# Cox model for TFE against trt_ab\nobj_TFE &lt;- coxph(Surv(time, status &gt; 0) ~ trt_ab, data = hfaction_TFE)\nsummary(obj_TFE)\n\n\n# Mortality vs TFE --------------------------------------------------------\n\nlibrary(ggsurvfit)\nlibrary(patchwork)\n\npD &lt;- survfit2(Surv(time, status) ~ trt_ab, data = hfaction_D) |&gt;\n  ggsurvfit(linewidth = 1) +\n  scale_ggsurvfit() +\n  scale_color_discrete(labels = c(\"Usual care\", \"Training\")) +\n  scale_x_continuous(\"Time (years)\", limits = c(0, 4)) +\n  labs(y = \"Overall survival\")\n\npTFE &lt;- survfit2(Surv(time, status &gt; 0) ~ trt_ab, data = hfaction_TFE) |&gt;\n  ggsurvfit(linewidth = 1) +\n  scale_ggsurvfit() +\n  scale_color_discrete(labels = c(\"Usual care\", \"Training\")) +\n  scale_x_continuous(\"Time (years)\", limits = c(0, 4)) +\n  labs(y = \"Hospitalization-free survival\")\n\n\npD + pTFE + plot_layout(guides = \"collect\") & \n  theme(\n    legend.position = \"top\", \n    legend.text = element_text(size = 12)\n    )\n\nggsave(\"images/intro_hfaction_unis.png\", width = 8, height = 4.5)\n\n# Total events (proportional mean) ----------------------------------------\n## fit proportional means model with death = 2 x hosp\nobj_ML &lt;- CompoML(hfaction$patid, hfaction$time, hfaction$status, \n                  hfaction$trt_ab, w = c(2, 1))\n## summary results\nobj_ML\n\n## plot model-based mean functions\nplot(obj_ML, 0, ylim= c(0, 5), xlim= c(0, 4), xlab=\"Time (years)\", \n     col = \"red\", lwd = 2)\nplot(obj_ML, 1, add = TRUE, col = \"blue\", lwd=2)\nlegend(0, 5, col = c(\"red\", \"blue\"), c(\"Usual care\",\"Training\"), lwd = 2)"
  },
  {
    "objectID": "intro.html#examples",
    "href": "intro.html#examples",
    "title": "1  Introduction",
    "section": "1.1 Examples",
    "text": "1.1 Examples"
  },
  {
    "objectID": "index.html#r-packages",
    "href": "index.html#r-packages",
    "title": "Statistical Methods for Composite Endpoints",
    "section": "R-packages",
    "text": "R-packages\nTo proceed, install/load the following packages\n\n# install packages --------------------------------\ninstall.packages(\"Wcompo\")\ninstall.packages(\"WR\")\ninstall.packages(\"rmt\")\ninstall.packages(\"WA\")\n# load packages -----------------------------------\nlibrary(tidyverse)\nlibrary(survival)\nlibrary(Wcompo)\nlibrary(WR)\nlibrary(rmt)\nlibrary(WA)"
  },
  {
    "objectID": "testing.html#r-code",
    "href": "testing.html#r-code",
    "title": "2  Hypothesis Testing",
    "section": "R-code",
    "text": "R-code\n\n\nShow the code\n##################################################################\n# This code generates the numerical results in  chapter 2       ##\n##################################################################\n\n\n# load the survival package\nlibrary(survival)\n\n# install and load the WR package for\n# 1. dataset hfaction_cpx9;\n# 2. function WRrec() for win ratio test (of recurrent events and death)\n# 3. functions base() and WRSS() for sample size calculation\n# install.packages(\"WR\")\nlibrary(WR)\nlibrary(tidyverse) # for data wrangling\n\n\n##### Read in HF-ACTION DATA########\n# same as rmt::hfaction used in chap 1 \n#  (except for status coding)\ndata(hfaction_cpx9)\nhfaction &lt;- hfaction_cpx9\nhead(hfaction)\n\n\n# count unique patients in each arm\nhfaction |&gt; \n  group_by(trt_ab) |&gt; \n  distinct(patid) |&gt; \n  count(trt_ab)\n  \n#### demo ############\nobj &lt;- WRrec(ID = hfaction$patid, time = hfaction$time, \n             status = hfaction$status, trt = hfaction$trt_ab,\n             strata = hfaction$age60, naive = TRUE)\n# summary results\nobj\n\n# LWR\nbeta &lt;- obj$log.WR\nse &lt;- obj$se\n# test\npval &lt;- 2*(1-pnorm(abs(beta/se)))\npval\n\n# NWR\nbeta.naive&lt;-obj$log.WR.naive\nse.naive&lt;-obj$se.naive\n# test\npval.naive&lt;-2*(1-pnorm(abs(beta.naive/se.naive)))\npval.naive\n\n\n# FWR\nbeta.FI&lt;-obj$log.WR.FI\nse.FI&lt;-obj$se.FI\n# test\npval.FI&lt;-2*(1-pnorm(abs(beta.FI/se.FI)))\npval.FI\n\n\n#################################\n# Win ratio analyses: tabulate  #\n#################################\n\ndata &lt;- hfaction \n### create a dataset with only the first hospitalization data.H1\n\n# hospitalization data\ntmpH &lt;- data[data$status==2,]\n# get the first record of each id\no &lt;- order(tmpH$patid,tmpH$time)\ntmpH &lt;- tmpH[o,]\ntmpFH &lt;- tmpH[!duplicated(tmpH$patid),]\n\n# combine it with mortality data\ndata.H1 &lt;- rbind(tmpFH,data[data$status!=2,])\no &lt;- order(data.H1$patid,data.H1$time)\ndata.H1 &lt;- data.H1[o,]\n\n\n# Function to create table for estimates of \n# PWR, NWR, FWR, and LWR, 95% CI nad p-values\n# ind: index for data\n# ind1: index for data.H1\n# r: number of decimal point\ngwr.fun=function(ind,ind1,r=2){\n\n# fit NWR, FWR, and LWR\nobj &lt;- WRrec(ID=data$patid[ind],time=data$time[ind],status=data$status[ind],\n          trt=data$trt_ab[ind],strata=data$age60[ind],naive=T)\n# fit sWR\nobj1 &lt;- WRrec(ID=data.H1$patid[ind1],time=data.H1$time[ind1],status=data.H1$status[ind1],\n          trt=data.H1$trt_ab[ind1],strata=data.H1$age60[ind1],naive=F)\n\n# critical value of p=0.05\nza &lt;- qnorm(0.975)\n\n## LWR\nbeta &lt;- obj$log.WR\nse &lt;- obj$se\ntheta &lt;- obj$theta\n\nr4 &lt;- c(paste0(round(100*theta[1],1),\"%\"),\n     paste0(round(100*theta[2],1),\"%\"),\n     paste0(round(exp(beta),r),\" (\",round(exp(beta-za*se),r),\", \",round(exp(beta+za*se),r),\")\"),\n     round(1-pchisq((beta/se)^2,1),3)\n)\n\n\n## PWR\nbeta1=obj1$log.WR\nse1=obj1$se\ntheta1=obj1$theta\n\nr1=c(paste0(round(100*theta1[1],1),\"%\"),\n     paste0(round(100*theta1[2],1),\"%\"),\n     paste0(round(exp(beta1),r),\" (\",round(exp(beta1-za*se1),r),\", \",round(exp(beta1+za*se1),r),\")\"),\n     round(1-pchisq((beta1/se1)^2,1),3)\n)\n\n## NWR\nbeta.naive=obj$log.WR.naive\nse.naive=obj$se.naive\ntheta.naive=obj$theta.naive\n\n\nr2=c(paste0(round(100*theta.naive[1],1),\"%\"),\n     paste0(round(100*theta.naive[2],1),\"%\"),\n     paste0(round(exp(beta.naive),r),\" (\",round(exp(beta.naive-za*se.naive),r),\", \",\n            round(exp(beta.naive+za*se.naive),r),\")\"),\n     round(1-pchisq((beta.naive/se.naive)^2,1),3)\n)\n\n\n\n\n## FWR\nbeta.FI=obj$log.WR.FI\nse.FI=obj$se.FI\ntheta.FI=obj$theta.FI\n\n\nr3=c(paste0(round(100*theta.FI[1],1),\"%\"),\n     paste0(round(100*theta.FI[2],1),\"%\"),\n     paste0(round(exp(beta.FI),r),\" (\",round(exp(beta.FI-za*se.FI),r),\", \",\n            round(exp(beta.FI+za*se.FI),r),\")\"),\n     round(1-pchisq((beta.FI/se.FI)^2,1),3)\n)\n\nresult=rbind(r1,r2,r3,r4)\nrownames(result)=c(\"PWR\",\"NWR\",\"FWR\",\"LWR\")\n\nreturn(result)\n}\n\n\n# Create table\n## Age &lt;= 60 years\nind=(data$age60==0)\nind1=(data.H1$age60==0)\nresult.lt60=gwr.fun(ind,ind1,r=2)\n\n## Age &gt; 60 years\nind=(data$age60==1)\nind1=(data.H1$age60==1)\nresult.ge60=gwr.fun(ind,ind1,r=2)\n\n## overall\nind=rep(T,nrow(data))\nind1=rep(T,nrow(data.H1))\nresult.all=gwr.fun(ind,ind1,r=2)\n\n# combine results \nresults=rbind(result.lt60,result.ge60,result.all)\ncolnames(results)=c(\"Win\", \"Loss\", \"Win ratio (95% CI)\", \"p-value\")\nnoquote(results)\n\n\n\n############################################################################\n#               Sample size calculation                                    #     \n############################################################################\n\n# get training arm data\npilot &lt;- hfaction |&gt; \n  filter(trt_ab == 1)\n# number of subjects\npilot |&gt; distinct(patid) |&gt; \n  count()\n\n############## estimate parameters ##############\n# Get the variables from pilot dataset\n# to estimate baseline parameters \n# lambda_D, lambda_H, kappa\n\noutcome_base &lt;- gumbel.est(pilot$patid, pilot$time / 12, pilot$status)\n\nlambda_D &lt;- outcome_base$lambda_D\nlambda_H &lt;- outcome_base$lambda_H\nkappa &lt;- outcome_base$kappa\n\nlambda_D\nlambda_H\nkappa\n\n## Kendall's rank correlation\n1 - 1/kappa\n#&gt; [1] 0.360812\n\n### demo ###################\n# set design parameters\ntau_b &lt;- 3\ntau &lt;- 4\nlambda_L &lt;- 0.01\n# use base() function to compute zeta2 and delta\n## may take up to 30s\nbparam &lt;- base(lambda_D, lambda_H, kappa, tau_b, tau, lambda_L)\n# compute sample size under HRs 0.8 and 0.9\n# for death and nonfatal event, respectively\nobj &lt;- WRSS(xi = log(c(0.9,0.8)), bparam = bparam, q =  0.5, alpha = 0.05,\n          power = 0.8)\n\nobj$n\n\n\n## effect size specification\nthetaD &lt;- seq(0.6, 0.95,by = 0.05) ## hazard ratio for death\nthetaH &lt;- seq(0.6, 0.95,by = 0.05) ## hazard ratio for hospitalization\n\n## create a matrix \"SS08\" for sample size powered at 80% \n## under each combination of thetaD and thetaH\nmD &lt;- length(thetaD)\nmH &lt;- length(thetaH)\nSS08 &lt;- matrix(NA, mD, mH)\nrownames(SS08) &lt;- thetaD\ncolnames(SS08) &lt;- thetaH\n## fill in the computed sample size values\nfor (i in 1:mD){\n  for (j in 1:mH){\n    ## sample size under hazard ratios thetaD[i] for death and thetaH[j] for hospitalization\n    SS08[i,j]&lt;-WRSS(xi=log(c(thetaD[i],thetaH[j])),bparam=bparam,q=0.5,alpha=0.05,\n                    power=0.8)$n\n  }\n}\n## print the calculated sample sizes\nprint(SS08)\n# 0.6     0.65      0.7     0.75       0.8     0.85      0.9      0.95\n# 0.6  198.1636 261.3528 351.2579 484.2468  691.0512 1034.785 1661.812  2976.570\n# 0.65 209.5088 278.6457 378.4143 528.6465  767.7521 1177.940 1961.252  3727.580\n# 0.7  220.9045 296.2334 406.4659 575.4320  850.7474 1338.718 2316.976  4708.455\n# 0.75 232.3703 314.1480 435.4823 624.8038  940.7326 1519.930 2742.885  6016.294\n# 0.8  243.9237 332.4188 465.5327 676.9740 1038.4859 1724.935 3257.279  7803.776\n# 0.85 255.5795 351.0732 496.6864 732.1690 1144.8828 1957.769 3884.618 10321.618\n# 0.9  267.3513 370.1374 529.0141 790.6317 1260.9129 2223.322 4658.150 14003.925\n# 0.95 279.2513 389.6366 562.5886 852.6243 1387.6996 2527.561 5623.948 19653.870\n\n## repeating the same calculation for power = 90%\nSS09 &lt;- matrix(NA, mD, mH)\nrownames(SS09) &lt;- thetaD\ncolnames(SS09) &lt; -thetaH\n## fill in the computed sample size values\nfor (i in 1:mD){\n  for (j in 1:mH){\n    ## sample size under hazard ratios thetaD[i] for death and thetaH[j] for hospitalization\n    SS09[i,j]&lt;-WRSS(xi=log(c(thetaD[i],thetaH[j])),bparam=bparam,q=0.5,alpha=0.05,\n                    power=0.9)$n\n  }\n}\n## print the calculated sample sizes\nprint(SS09)\n# [,1]     [,2]     [,3]      [,4]      [,5]     [,6]     [,7]      [,8]\n# 0.6  265.2849 349.8773 470.2346  648.2691  925.1215 1385.283 2224.695  3984.783\n# 0.65 280.4729 373.0275 506.5893  707.7076 1027.8022 1576.928 2625.560  4990.172\n# 0.7  295.7284 396.5725 544.1425  770.3402 1138.9094 1792.164 3101.773  6303.285\n# 0.75 311.0780 420.5551 582.9873  836.4350 1259.3740 2034.755 3671.945  8054.111\n# 0.8  326.5446 445.0145 623.2161  906.2762 1390.2379 2309.198 4360.573 10447.042\n# 0.85 342.1484 469.9874 664.9221  980.1666 1532.6732 2620.897 5200.401 13817.718\n# 0.9  357.9075 495.5089 708.1999 1058.4316 1688.0046 2976.398 6235.942 18747.282\n# 0.95 373.8383 521.6128 753.1465 1141.4221 1857.7360 3383.687 7528.871 26310.956\n\noldpar &lt;- par(mfrow = par(\"mfrow\"))\npar(mfrow=c(1,2))\npersp(thetaD, thetaH, SS08/1000, theta = 50, phi = 15, expand = 0.8, col = \"gray\",\n      ltheta = 180, lphi=180, shade = 0.75,\n      ticktype = \"detailed\",\n      xlab = \"\\n HR on Death\", ylab = \"\\n HR on Hospitalization\",\n      zlab=paste0(\"\\n Sample Size (10e3)\"),\n      main=\"Power = 80%\",\n      zlim=c(0, 26)\n)\npersp(thetaD, thetaH, SS09/1000, theta = 50, phi = 15, expand = 0.8, col = \"gray\",\n      ltheta = 180, lphi=180, shade = 0.75,\n      ticktype = \"detailed\",\n      xlab = \"\\nHR on Death\", ylab = \"\\nHR on Hospitalization\",\n      zlab=paste0(\"\\n Sample Size (10e3)\"),\n      main=\"Power = 90%\",\n      zlim=c(0, 26)\n)"
  }
]